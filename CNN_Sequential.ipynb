{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "022974e8-ca2d-47c4-8784-d0bb279595ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dog images in training data : 10000\n",
      "Total number of cat images in training data : 10000\n",
      "\n",
      "Total number of dog images in validation data : 2500\n",
      "Total number of cat images in validation data : 2500\n",
      "\n",
      "Total number of unknown images in test data : 500\n"
     ]
    }
   ],
   "source": [
    "# Basic\n",
    "import os\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# visuals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "datasetzipfile = \"datasets.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(datasetzipfile):\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(datasetzipfile, 'r') as zip_ref:\n",
    "        # Iterate through each file in the zip archive\n",
    "        for file_info in zip_ref.infolist():\n",
    "            # Check if the file already exists in the current directory\n",
    "            if not os.path.exists(file_info.filename):\n",
    "                zip_ref.extract(file_info)\n",
    "else:\n",
    "    print(f\"{datasetzipfile} does not exist.\")\n",
    "\n",
    "train_path_dog = \"datasets/train/dog\"\n",
    "train_path_cat = \"datasets/train/cat\"\n",
    "valid_path_dog = \"datasets/val/dog\"\n",
    "valid_path_cat = \"datasets/val/cat\"\n",
    "\n",
    "test_path = \"datasets/test\"\n",
    "\n",
    "#Count the Data Provided\n",
    "def count_files_in_directory(path):\n",
    "    try:\n",
    "        # List all entries in the specified directory\n",
    "        all_entries = os.listdir(path)\n",
    "        \n",
    "        # Count only the files (exclude directories)\n",
    "        total_files = sum(1 for entry in all_entries if os.path.isfile(os.path.join(path, entry)))\n",
    "        \n",
    "        return total_files\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Specify the directory path\n",
    "print(\"Total number of dog images in training data :\", count_files_in_directory(train_path_dog))\n",
    "print(\"Total number of cat images in training data :\", count_files_in_directory(train_path_cat))\n",
    "print()\n",
    "print(\"Total number of dog images in validation data :\", count_files_in_directory(valid_path_dog))\n",
    "print(\"Total number of cat images in validation data :\", count_files_in_directory(valid_path_cat))\n",
    "print()\n",
    "print(\"Total number of unknown images in test data :\", count_files_in_directory(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd54bc8f-98f7-4d80-b491-4fbf28a2969e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "{'Cat': 0, 'Dog': 1}\n",
      "2\n",
      "20000\n"
     ]
    }
   ],
   "source": [
    "# Define your image size and batch size\n",
    "image_size = 128  # or the size your model expects\n",
    "image_channel = 3\n",
    "bat_size = 64 # batch size of your choice\n",
    "\n",
    "# Import the ImageDataGenerator class\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create an ImageDataGenerator object for the validation set\n",
    "validation_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# Create an ImageDataGenerator object for the test set\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "# Create an ImageDataGenerator object for the training set\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    rotation_range=15,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\"datasets/train\", \n",
    "                                                    target_size = (image_size, image_size),\n",
    "                                                    classes=['Cat' , 'Dog'],\n",
    "                                                    class_mode='binary',\n",
    "                                                    batch_size=bat_size,\n",
    "                                                    #save_to_dir=aug_data_path,\n",
    "                                                    #save_prefix='aug_',\n",
    "                                                    #save_format=\"jpg\",\n",
    "                                                    seed = 1\n",
    "                                                    \n",
    "                                                    )\n",
    "print(train_generator.class_indices)\n",
    "print(train_generator.num_classes)\n",
    "print(train_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "531bb949-fd0e-468c-9dcb-eb3288f52c0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 images belonging to 2 classes.\n",
      "{'Cat': 0, 'Dog': 1}\n",
      "2\n",
      "5000\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_datagen.flow_from_directory(\"datasets/val\", \n",
    "                                                    target_size = (image_size, image_size),\n",
    "                                                    classes=['Cat' , 'Dog'],\n",
    "                                                    class_mode='binary',\n",
    "                                                    batch_size=bat_size,\n",
    "                                                    seed = 1 )\n",
    "print(validation_generator.class_indices)\n",
    "print(validation_generator.num_classes)\n",
    "print(validation_generator.samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "43b519c1-d5f3-4151-8595-32fbbb8a3b52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All filenames are valid.\n",
      "Found 500 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# Get a list of all image filenames in the test directory\n",
    "filenames = os.listdir(test_path)\n",
    "filepaths = [os.path.join(test_path, fname) for fname in filenames]\n",
    "\n",
    "# Check for invalid files by comparing filenames\n",
    "valid_filenames = os.listdir(test_path)\n",
    "\n",
    "# Create a DataFrame with filenames (no need for labels)\n",
    "df_test = pd.DataFrame({\n",
    "    'filename': filenames\n",
    "})\n",
    "\n",
    "# Filter out filenames that don't exist in the directory\n",
    "invalid_filenames = df_test[~df_test['filename'].isin(valid_filenames)]\n",
    "\n",
    "# Print invalid filenames\n",
    "if len(invalid_filenames) > 0:\n",
    "    print(\"Invalid filenames:\")\n",
    "    print(invalid_filenames['filename'])\n",
    "else:\n",
    "    print(\"All filenames are valid.\")\n",
    "\n",
    "test_generator = test_datagen.flow_from_dataframe(\n",
    "    dataframe=df_test,\n",
    "    directory=test_path,          # Path to the directory with images\n",
    "    x_col='filename',             # Column containing the filenames\n",
    "    y_col=None,                   # No labels for prediction\n",
    "    target_size= (image_size, image_size),         # Resize the images\n",
    "    batch_size=bat_size,\n",
    "    class_mode=None,              # No labels, since we're predicting\n",
    "    shuffle=False,                # Keep the order of files\n",
    "    seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad4d388-5557-4f33-aa58-ef28afd88175",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">61</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25088</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">9216</span>)           │   <span style=\"color: #00af00; text-decoration-color: #00af00\">231,220,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">589,888</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m126\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m63\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m61\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m30\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25088\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m9216\u001b[0m)           │   \u001b[38;5;34m231,220,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │       \u001b[38;5;34m589,888\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,903,425</span> (884.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m231,903,425\u001b[0m (884.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">231,903,425</span> (884.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m231,903,425\u001b[0m (884.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example architecture adjustment\n",
    "model = Sequential()\n",
    "\n",
    "# Add convolutional layers (your current structure)\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# Flatten the output\n",
    "model.add(Flatten())\n",
    "\n",
    "# Adjust this layer's input size based on the flattened output\n",
    "model.add(Dense(9216, activation='relu'))  # Match this number to the output of the flatten layer\n",
    "\n",
    "# Add more dense layers if needed\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))  # For binary classification (cats vs dogs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15b25a94-6ba7-4fe2-9ab1-019bd2b13272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkabilan/Desktop/Mini-Proj_IE4483.nosync/myenv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 14s/step - accuracy: 0.4856 - loss: 2.7461 - val_accuracy: 0.4938 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 2/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m197s\u001b[0m 18s/step - accuracy: 0.5283 - loss: 0.6940 - val_accuracy: 0.4766 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 3/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 13s/step - accuracy: 0.4934 - loss: 0.6937 - val_accuracy: 0.5219 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 4/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 13s/step - accuracy: 0.4801 - loss: 0.6932 - val_accuracy: 0.5109 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 5/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.4856 - loss: 0.6931 \n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 17s/step - accuracy: 0.4869 - loss: 0.6931 - val_accuracy: 0.4891 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 6/15\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 15s/step - accuracy: 0.5056 - loss: 0.6931 - val_accuracy: 0.5016 - val_loss: 0.6932 - learning_rate: 5.0000e-04\n"
     ]
    }
   ],
   "source": [
    "learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_accuracy',\n",
    "                                            patience=2,\n",
    "                                            factor=0.5,\n",
    "                                            min_lr = 0.00001,\n",
    "                                            verbose = 1)\n",
    "\n",
    "early_stoping = EarlyStopping(monitor='val_loss',patience= 3,restore_best_weights=True,verbose=0)\n",
    "\n",
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "cat_dog = model.fit(train_generator,\n",
    "                    validation_data = validation_generator, \n",
    "                    callbacks=[early_stoping,learning_rate_reduction],\n",
    "                    epochs = 15,\n",
    "                    #steps_per_epoch = len(train_generator),\n",
    "                    #validation_steps = len(validation_generator),\n",
    "                    steps_per_epoch = 10, #312\n",
    "                    validation_steps = 10, #78\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30b5511-545d-4317-9228-1cdcd0674b05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
