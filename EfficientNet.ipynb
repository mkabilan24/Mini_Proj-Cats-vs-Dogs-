{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9f89339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of dog images in training data : 10000\n",
      "Total number of cat images in training data : 10000\n",
      "\n",
      "Total number of dog images in validation data : 2500\n",
      "Total number of cat images in validation data : 2500\n",
      "\n",
      "Total number of unknown images in test data : 500\n"
     ]
    }
   ],
   "source": [
    "# Basic\n",
    "import os\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# visuals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping\n",
    "\n",
    "datasetzipfile = \"datasets.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(datasetzipfile):\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(datasetzipfile, 'r') as zip_ref:\n",
    "        # Iterate through each file in the zip archive\n",
    "        for file_info in zip_ref.infolist():\n",
    "            # Check if the file already exists in the current directory\n",
    "            if not os.path.exists(file_info.filename):\n",
    "                zip_ref.extract(file_info)\n",
    "else:\n",
    "    print(f\"{datasetzipfile} does not exist.\")\n",
    "\n",
    "train_path_dog = \"datasets/train/dog\"\n",
    "train_path_cat = \"datasets/train/cat\"\n",
    "valid_path_dog = \"datasets/val/dog\"\n",
    "valid_path_cat = \"datasets/val/cat\"\n",
    "\n",
    "test_path = \"datasets/test\"\n",
    "\n",
    "#Count the Data Provided\n",
    "def count_files_in_directory(path):\n",
    "    try:\n",
    "        # List all entries in the specified directory\n",
    "        all_entries = os.listdir(path)\n",
    "        \n",
    "        # Count only the files (exclude directories)\n",
    "        total_files = sum(1 for entry in all_entries if os.path.isfile(os.path.join(path, entry)))\n",
    "        \n",
    "        return total_files\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Specify the directory path\n",
    "print(\"Total number of dog images in training data :\", count_files_in_directory(train_path_dog))\n",
    "print(\"Total number of cat images in training data :\", count_files_in_directory(train_path_cat))\n",
    "print()\n",
    "print(\"Total number of dog images in validation data :\", count_files_in_directory(valid_path_dog))\n",
    "print(\"Total number of cat images in validation data :\", count_files_in_directory(valid_path_cat))\n",
    "print()\n",
    "print(\"Total number of unknown images in test data :\", count_files_in_directory(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a9d4dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mkabilan/Desktop/Mini-Proj_IE4483.nosync/myenv/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m548s\u001b[0m 872ms/step - accuracy: 0.5011 - loss: 0.7049 - val_accuracy: 0.5000 - val_loss: 0.6933 - learning_rate: 0.0010\n",
      "Epoch 2/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m572s\u001b[0m 915ms/step - accuracy: 0.4954 - loss: 0.7022 - val_accuracy: 0.5000 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 3/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m584s\u001b[0m 935ms/step - accuracy: 0.5026 - loss: 0.6994 - val_accuracy: 0.5000 - val_loss: 0.6928 - learning_rate: 0.0010\n",
      "Epoch 4/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m645s\u001b[0m 1s/step - accuracy: 0.5038 - loss: 0.7000 - val_accuracy: 0.5000 - val_loss: 0.6984 - learning_rate: 0.0010\n",
      "Epoch 5/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m660s\u001b[0m 1s/step - accuracy: 0.5041 - loss: 0.6986 - val_accuracy: 0.5000 - val_loss: 0.6940 - learning_rate: 0.0010\n",
      "Epoch 6/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m682s\u001b[0m 1s/step - accuracy: 0.5022 - loss: 0.6961 - val_accuracy: 0.4996 - val_loss: 0.6937 - learning_rate: 2.0000e-04\n",
      "Epoch 7/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m574s\u001b[0m 919ms/step - accuracy: 0.4956 - loss: 0.6972 - val_accuracy: 0.5566 - val_loss: 0.6925 - learning_rate: 2.0000e-04\n",
      "Epoch 8/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m482s\u001b[0m 771ms/step - accuracy: 0.5070 - loss: 0.6962 - val_accuracy: 0.5000 - val_loss: 0.6928 - learning_rate: 2.0000e-04\n",
      "Epoch 9/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m474s\u001b[0m 759ms/step - accuracy: 0.5056 - loss: 0.6961 - val_accuracy: 0.5050 - val_loss: 0.6925 - learning_rate: 2.0000e-04\n",
      "Epoch 10/10\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m459s\u001b[0m 734ms/step - accuracy: 0.4997 - loss: 0.6961 - val_accuracy: 0.5722 - val_loss: 0.6924 - learning_rate: 4.0000e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Define input image size (you can adjust this based on your dataset)\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "# Data Augmentation using ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the train and validation data generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'datasets/train',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'datasets/val',\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='binary')\n",
    "\n",
    "# Create the EfficientNetB0 model (pre-trained on ImageNet)\n",
    "base_model = EfficientNetB0(include_top=False, input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3), weights='imagenet')\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    GlobalAveragePooling2D(),\n",
    "    Dropout(0.5),  # Dropout to prevent overfitting\n",
    "    Dense(1, activation='sigmoid')  # Binary classification: dog or cat\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Add callbacks for learning rate reduction and early stopping\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=2, min_lr=0.00001)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator,\n",
    "    callbacks=[reduce_lr, early_stopping]\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "model.save('efficientnet_cat_dog_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ad918f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Found 0 images belonging to 1 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb3_notop.h5\n",
      "\u001b[1m43941136/43941136\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
      "Epoch 1/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1779s\u001b[0m 3s/step - accuracy: 0.5056 - loss: 2.0790 - val_accuracy: 0.5000 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 2/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2063s\u001b[0m 3s/step - accuracy: 0.4970 - loss: 0.7077 - val_accuracy: 0.5000 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 3/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1825s\u001b[0m 3s/step - accuracy: 0.4955 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6932 - learning_rate: 0.0010\n",
      "Epoch 4/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1795s\u001b[0m 3s/step - accuracy: 0.5017 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 5/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1892s\u001b[0m 3s/step - accuracy: 0.5012 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 2.0000e-04\n",
      "Epoch 6/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1782s\u001b[0m 3s/step - accuracy: 0.4986 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 2.0000e-04\n",
      "Epoch 7/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1739s\u001b[0m 3s/step - accuracy: 0.5008 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 2.0000e-04\n",
      "Epoch 8/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1718s\u001b[0m 3s/step - accuracy: 0.5028 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 9/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1716s\u001b[0m 3s/step - accuracy: 0.5061 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 10/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1696s\u001b[0m 3s/step - accuracy: 0.5018 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 11/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1677s\u001b[0m 3s/step - accuracy: 0.5007 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 12/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1704s\u001b[0m 3s/step - accuracy: 0.4997 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 13/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1691s\u001b[0m 3s/step - accuracy: 0.4906 - loss: 0.6932 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n",
      "Epoch 14/25\n",
      "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1650s\u001b[0m 3s/step - accuracy: 0.4999 - loss: 0.6931 - val_accuracy: 0.5000 - val_loss: 0.6931 - learning_rate: 1.0000e-04\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must provide at least one structure",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 82\u001b[0m\n\u001b[1;32m     74\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     75\u001b[0m     train_generator,\n\u001b[1;32m     76\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mvalid_generator,\n\u001b[1;32m     77\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[1;32m     78\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39m[early_stop, reduce_lr]\n\u001b[1;32m     79\u001b[0m )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Evaluate the model on test data\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m test_loss, test_acc \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_acc\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Mini-Proj_IE4483.nosync/myenv/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Desktop/Mini-Proj_IE4483.nosync/myenv/lib/python3.10/site-packages/keras/src/tree/optree_impl.py:76\u001b[0m, in \u001b[0;36mmap_structure\u001b[0;34m(func, *structures)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`func` must be callable. Received: func=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m structures:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMust provide at least one structure\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m structures[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m     78\u001b[0m     assert_same_structure(structures[\u001b[38;5;241m0\u001b[39m], other, check_types\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[0;31mValueError\u001b[0m: Must provide at least one structure"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.applications import EfficientNetB3\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Paths to training, validation, and test directories\n",
    "train_path = \"datasets/train\"\n",
    "valid_path = \"datasets/val\"\n",
    "test_path = \"datasets/test\"\n",
    "\n",
    "# ImageDataGenerator for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data Generators for loading images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(300, 300),  # Input size for EfficientNetB3\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_path,\n",
    "    target_size=(300, 300),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load EfficientNetB3 with pretrained ImageNet weights\n",
    "base_model = EfficientNetB3(weights='imagenet', include_top=False, input_shape=(300, 300, 3))\n",
    "\n",
    "# Freeze the base model's layers to avoid training them\n",
    "base_model.trainable = False\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),  # Flatten the output layer from EfficientNetB3\n",
    "    Dense(128, activation='relu'),  # Add a fully connected layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for early stopping and learning rate reduction\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=25,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_generator)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3757cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 images belonging to 2 classes.\n",
      "Found 5000 images belonging to 2 classes.\n",
      "Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb4_notop.h5\n",
      "\u001b[1m71686520/71686520\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n",
      "Epoch 1/25\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Data generators for loading images from directories\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_path,\n",
    "    target_size=(380, 380),  # Input size for EfficientNetB4\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_path,\n",
    "    target_size=(380, 380),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "# Load EfficientNetB4 with ImageNet weights\n",
    "base_model = EfficientNetB4(weights='imagenet', include_top=False, input_shape=(380, 380, 3))\n",
    "\n",
    "# Unfreeze the base model to fine-tune it\n",
    "base_model.trainable = True  # Allow training of all layers\n",
    "\n",
    "# Build the model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),  # Flatten the output from EfficientNetB4\n",
    "    Dense(128, activation='relu'),  # Add a dense layer\n",
    "    Dropout(0.3),  # Dropout for regularization\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks for learning rate reduction and early stopping\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model (no test data used here)\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=valid_generator,\n",
    "    epochs=25,\n",
    "    callbacks=[early_stop, reduce_lr]\n",
    ")\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_acc = model.evaluate(valid_generator)\n",
    "print(f\"Validation accuracy: {val_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
