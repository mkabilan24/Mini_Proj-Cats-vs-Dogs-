{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d027b27b-7d0c-4522-b255-a0fd06829090",
   "metadata": {},
   "source": [
    "## Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991bd1a-c459-4a42-aed5-55275631756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "import os\n",
    "from os import makedirs\n",
    "from os import listdir\n",
    "from shutil import copyfile\n",
    "from random import seed\n",
    "from random import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# visuals\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.image import imread\n",
    "from PIL import Image\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix,ConfusionMatrixDisplay\n",
    "\n",
    "# Tensorflow\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense,MaxPooling2D,Dropout,Flatten,BatchNormalization,Conv2D\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau,EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb27e4c8-c4a9-4786-aa36-4116365eb1d8",
   "metadata": {},
   "source": [
    "## Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f07091f-947f-456f-9743-251b10be0a4f",
   "metadata": {},
   "source": [
    "#### Unzip the File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "733ffe42-1553-4196-9b60-76a44b49f3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetzipfile = \"datasets.zip\"\n",
    "\n",
    "# Check if the zip file exists\n",
    "if os.path.exists(datasetzipfile):\n",
    "    # Open the zip file in read mode\n",
    "    with zipfile.ZipFile(datasetzipfile, 'r') as zip_ref:\n",
    "        # Iterate through each file in the zip archive\n",
    "        for file_info in zip_ref.infolist():\n",
    "            # Check if the file already exists in the current directory\n",
    "            if not os.path.exists(file_info.filename):\n",
    "                zip_ref.extract(file_info)\n",
    "else:\n",
    "    print(f\"{datasetzipfile} does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77718680-09d6-4fb7-9611-c2a79df5de9f",
   "metadata": {},
   "source": [
    "#### Set Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b2c925-8d7f-4d0e-b9a1-2a05d96e5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path_dog = \"datasets/train/dog\"\n",
    "train_path_cat = \"datasets/train/cat\"\n",
    "valid_path_dog = \"datasets/val/dog\"\n",
    "valid_path_cat = \"datasets/val/cat\"\n",
    "\n",
    "test_path = \"datasets/test\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b8d214-88b4-45a8-8272-c5b84a93acda",
   "metadata": {},
   "source": [
    "## Data Exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc08352e-3d9a-490a-bef7-792c30c4fc0c",
   "metadata": {},
   "source": [
    "#### Function to check path (Unused)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2204bf-42db-4d7d-813d-68abe3aff0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_in_directory(path):\n",
    "    try:\n",
    "        # List all files in the specified directory\n",
    "        files = os.listdir(path)\n",
    "        \n",
    "        # Filter out directories, only keep files\n",
    "        files = [f for f in files if os.path.isfile(os.path.join(path, f))]\n",
    "        \n",
    "        return files\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "#files = list_files_in_directory(train_path_dog)\n",
    "#print(\"Files in directory:\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc617595-ab27-44f6-a809-45ad2db5a19f",
   "metadata": {},
   "source": [
    "#### Function to Display Head of Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a630e6d-eb51-4e8f-ae25-6e6611a7c73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_files_head(image_dir):\n",
    "    filenames = os.listdir(image_dir)\n",
    "    labels = [x.split(\".\")[0] for x in filenames]\n",
    "    \n",
    "    data = pd.DataFrame({\"filename\": filenames, \"label\": labels})\n",
    "    \n",
    "    return data.head()\n",
    "\n",
    "#display_files_head(train_path_dog)\n",
    "#display_files_head(train_path_cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42743b78-7594-4cb4-b34a-f4839c2ab8a6",
   "metadata": {},
   "source": [
    "#### Visualisation of Dogs from Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60d1427-3bb7-45a4-b10c-4e09ff862373",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Images of Dogs from Train Dataset\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# Initialize a counter for the number of images plotted\n",
    "count = 0\n",
    "\n",
    "for i in range(10):\n",
    "    filename = f'datasets/train/dog/dog.{i}.jpg'\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(filename):\n",
    "        plt.subplot(1, 10, count + 1)  # Create a subplot for the existing image\n",
    "        image = imread(filename)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Dog' + str(i), fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        count += 1  # Increment the counter for each plotted image\n",
    "\n",
    "# Adjust the layout to accommodate the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb2f5eb-f4a7-4018-971d-75a803ccb5de",
   "metadata": {},
   "source": [
    "#### Visualisation of Cats from Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5d78b1-ffef-4407-9225-d76c67329455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualise Images of Cats from Train Dataset\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "plt.subplots_adjust(hspace=0.4)\n",
    "\n",
    "# Initialize a counter for the number of images plotted\n",
    "count = 0\n",
    "\n",
    "for i in range(10):\n",
    "    filename = f'datasets/train/cat/cat.{i}.jpg'\n",
    "    \n",
    "    # Check if the file exists\n",
    "    if os.path.exists(filename):\n",
    "        plt.subplot(1, 10, count + 1)  # Create a subplot for the existing image\n",
    "        image = imread(filename)\n",
    "        plt.imshow(image)\n",
    "        plt.title('Cat' + str(i), fontsize=12)\n",
    "        plt.axis('off')\n",
    "        \n",
    "        count += 1  # Increment the counter for each plotted image\n",
    "\n",
    "# Adjust the layout to accommodate the images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a1d80f-0c7e-479d-8c53-2c4f350272c1",
   "metadata": {},
   "source": [
    "#### Training, Validation and Test Data Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872f1751-c008-435c-9352-b556b799830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Count the Data Provided\n",
    "def count_files_in_directory(path):\n",
    "    try:\n",
    "        # List all entries in the specified directory\n",
    "        all_entries = os.listdir(path)\n",
    "        \n",
    "        # Count only the files (exclude directories)\n",
    "        total_files = sum(1 for entry in all_entries if os.path.isfile(os.path.join(path, entry)))\n",
    "        \n",
    "        return total_files\n",
    "    except Exception as e:\n",
    "        return str(e)\n",
    "\n",
    "# Specify the directory path\n",
    "print(\"Total number of dog images in training data :\", count_files_in_directory(train_path_dog))\n",
    "print(\"Total number of cat images in training data :\", count_files_in_directory(train_path_cat))\n",
    "print()\n",
    "print(\"Total number of dog images in validation data :\", count_files_in_directory(valid_path_dog))\n",
    "print(\"Total number of cat images in validation data :\", count_files_in_directory(valid_path_cat))\n",
    "print()\n",
    "print(\"Total number of unknown images in test data :\", count_files_in_directory(test_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3fca4a8-b568-4110-a621-f0b86a9a47e1",
   "metadata": {},
   "source": [
    "### Continue...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fbe91-eb2e-433c-8806-10fbe6b4ccee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "image_size = 150  # Size to which the images will be resized\n",
    "batch_size = 32   # Number of images to be yielded from the generator per batch\n",
    "\n",
    "# Data Generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                    rotation_range=15,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    fill_mode='nearest')\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Load datasets\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'datasets/train/',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary'  # Binary classification (dog vs. cat)\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    'datasets/val/',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'datasets/test/',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=None,  # No labels expected for test set\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# CNN Model\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(image_size, image_size, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Conv2D(256, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    Flatten(),\n",
    "    \n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(1, activation='sigmoid')  # Use sigmoid for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Callbacks\n",
    "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=2, factor=0.5, min_lr=0.00001, verbose=1)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True, verbose=1)\n",
    "\n",
    "# Train the model\n",
    "cat_dog = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[early_stopping, learning_rate_reduction],\n",
    "    epochs=30,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    validation_steps=len(val_generator)\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "print(f'Test accuracy: {test_accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
